{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6da53d85-359b-446f-b0c7-74fb400d3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import(\n",
    "    classification_report, accuracy_score, roc_auc_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05c1b8de-02b0-4bb7-b124-57a5988fc1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8be610f1-81d4-4b27-ae89-120e0f671999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_dataset(filepath):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"LOAD AND  EXPLORE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(\"Shape of the dataset\")\n",
    "    print(df.shape)\n",
    "    print(\"\\nCheck for missing values\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nFirst five rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDescriptive stats\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nDataset Info\")\n",
    "    print(df.info())\n",
    "    print(\"\\nExited Distribution:\")\n",
    "    print(df[\"Exited\"].value_counts())\n",
    "    print(\"\\nExited percebtage Distribution:\")\n",
    "    print(df[\"Exited\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef04ce93-07cb-40a9-af26-b48e8705b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_features(df):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"IDENTIFY FEATURE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "    # features to be droped(not useful)\n",
    "    feature_to_drop = [\n",
    "        \"CustomerId\",\n",
    "        \"Surname\"\n",
    "    ]\n",
    "\n",
    "    numerical_features = [\n",
    "        \"CreditScore\",\n",
    "        \"Age\",\n",
    "        \"Tenure\",\n",
    "        \"EstimatedSalary\",\n",
    "        \"Balance\",\n",
    "        \"NumOfProducts\",\n",
    "        \"ServiceRating\"\n",
    "    ]\n",
    "\n",
    "    categorical_features = [\n",
    "        \"Geography\",\n",
    "        \"Gender\",\n",
    "        \"HasCrCard\",\n",
    "        \"IsActiveMember\"\n",
    "    ]\n",
    "    print(\"\\nFeatures to drop :\",feature_to_drop)\n",
    "    print(\"\\nNumerical features :\", numerical_features )\n",
    "    print(\"Categirical features :\", categorical_features)\n",
    "\n",
    "    return(numerical_features, categorical_features, feature_to_drop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5126705a-71c4-4ebe-9f22-fdc02dcfbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, numerical_features, categorical_features, feature_to_drop):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PREPARE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # drop unnecessary columns\n",
    "    df_model = df.drop(columns=feature_to_drop)\n",
    "\n",
    "    # feature to use\n",
    "    X = df_model.drop(\"Exited\", axis=1)\n",
    "    # target\n",
    "    y = df_model[\"Exited\"]\n",
    "\n",
    "    print(\"\\nFeature shape:\", X.shape)\n",
    "    print(\"\\nTarget shape :\", y.shape)\n",
    "    print(\"\\nFeature columns list:\", list(X.columns))\n",
    "\n",
    "    return X, y, list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5df4796e-a734-4fa9-bda8-a0d9daf029c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprossesing_pipeline(numerical_features, categorical_features):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CREATING PREPROCESSNG PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # numerical features pipeline\n",
    "    numerical_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # categorical features pipeline\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    # column preprocesing\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numerical_pipeline, numerical_features),\n",
    "        (\"cat\", categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62bc8015-9052-4fcc-b521-9d5d4796ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SPLITING DATA INTO TEST/TRAIN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    print(\"\\nTraining set size\", X_train.shape[0])\n",
    "    print(\"Testing set size\", X_test.shape[0])\n",
    "    print(\"Train churn distribution\", y_train.value_counts())\n",
    "    print(\"Test churn distribution\", y_test.value_counts())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9bd11f9-a21d-4a23-a1f0-3aed85f54289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_pipeline(preprocessor):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CREATING MODEL PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    model_pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(\n",
    "            max_iter= 1000,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\",\n",
    "            solver=\"lbfgs\"\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print(\"\\nModel pipeline created successfully\")\n",
    "\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe57f099-3666-4588-8b7c-5197a3eb71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_pipeline, X_train, y_train):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nModel train successfully\")\n",
    "\n",
    "    #get name steps preprocessing\n",
    "    try:\n",
    "        num_features = model_pipeline.named_steps[\"preprocessor\"].transformers_[0][2]\n",
    "        cat_features = model_pipeline.named_steps[\"preprocessor\"].transformers_[1][2]\n",
    "\n",
    "        # get name stepd onehotencoder\n",
    "        onehot_encoder = model_pipeline.named_steps[\"preprocessor\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "        cat_features_names = onehot_encoder.get_feature_names_out(cat_features)\n",
    "\n",
    "        all_features_name = list(num_features) + list(cat_features_names)\n",
    "\n",
    "        # get coefficient\n",
    "        coefficient = model_pipeline.named_steps[\"classifier\"].coef_[0]\n",
    "        print(\"\\nTop 10 most important features (by coefficient magnitude)\")\n",
    "        feature_importance = pd.DataFrame({\n",
    "            \"feature\": all_features_name,\n",
    "            \"coefficient\": coefficient\n",
    "        }).sort_values(\"coefficient\", key=abs, ascending=False)\n",
    "        print(feature_importance.head(10).to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Can not extract  features names {e}\")\n",
    "\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e2c7dcb-a863-47e7-a909-025e60cd5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_pipeline, X_train, X_test, y_train, y_test):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EVALUATING MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    #predicted model\n",
    "    y_train_pred = model_pipeline.predict(X_train)\n",
    "    y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "    # predicted model prob\n",
    "    y_train_proba = model_pipeline.predict_proba(X_train)[:, 1]\n",
    "    y_test_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # metrics\n",
    "    y_train_acc_score = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_acc_score = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    y_train_roc_score = roc_auc_score(y_train, y_train_proba)\n",
    "    y_test_roc_score = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "    print(\"\\nMETRICS EVALUATION\")\n",
    "    print(f\"\\nTrain accuracy score:, {float(y_train_acc_score):.4f}\")\n",
    "    print(f\"\\nTest accuracy score:, {float(y_test_acc_score):.4f}\")\n",
    "    print(f\"\\nTrain ROC score:, {float(y_train_roc_score):.4f}\")\n",
    "    print(f\"\\nTest ROC score:, {float(y_test_roc_score):.4f}\")\n",
    "\n",
    "    print(\"\\nCLASSIFICATION OF TRAIN SIZE\")\n",
    "    print(\"\\nclassificatin report\\n\", classification_report(y_train, y_train_pred, target_names=[\"Retained\", \"Churned\"]))\n",
    "\n",
    "    print(\"\\nCLASSIFICATION OF TRAIN SIZE\")\n",
    "    print(\"\\nclassificatin report\\n\", classification_report(y_test, y_test_pred, target_names=[\"Retained\", \"Churned\"]))\n",
    "\n",
    "    # cross validation\n",
    "    cv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring=\"roc_auc\")\n",
    "    print(\"\\nCross Validation (5-folds)\")\n",
    "    print(f\" R2 scores: {cv_scores}\")\n",
    "    print(f\" Cross validation mean: {cv_scores.mean():.4f}\")\n",
    "    print(f\" Cross validation STD: {cv_scores.std():.4f}\")\n",
    "\n",
    "    metrics = {\n",
    "        \"y_train_acc_score\":  y_train_acc_score,\n",
    "        \"y_test_acc_score\": y_test_acc_score,\n",
    "        \"y_train_roc_score\": y_train_roc_score,\n",
    "        \"y_test_roc_score\": y_test_roc_score,\n",
    "        \"y_train_pred\":  y_train_pred,\n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        \"y_train_proba\": y_train_proba,\n",
    "        \"y_test_proba\": y_test_proba,\n",
    "        \"cv_scores\": cv_scores \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b8fef53-fe8d-4991-a153-19973063b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_artifact(model_pipeline, feature_columns):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SAVING MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    joblib.dump(model_pipeline, \"churned_model_prediction.pkl\")\n",
    "    print(\"Churned prediction model saved successfully\")\n",
    "\n",
    "    joblib.dump(feature_columns, \"churn_feature_columns.pkl\")\n",
    "    print(\"Feature columns saved successfully\")\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ALL MODEL ARTIFACT SAVED SUCCESSFULLY\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00b8f06f-d42c-4c11-a8b7-7fc560ac2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_churn(customer_data):\n",
    "    model_pipeline = joblib.load(\"churned_model_prediction.pkl\")\n",
    "    feature_columns = joblib.load(\"churn_feature_columns.pkl\")\n",
    "\n",
    "    customer_df = pd.DataFrame([customer_data])\n",
    "\n",
    "    for feature in feature_columns:\n",
    "        if feature not in customer_df.columns:\n",
    "            raise ValueError(f\"Missing required feature {feature}\")\n",
    "\n",
    "    customer_df = customer_df[feature_columns]\n",
    "\n",
    "    prediction = model_pipeline.predict(customer_df)[0]\n",
    "    probability = model_pipeline.predict_proba(customer_df)[0]\n",
    "\n",
    "    result = {\n",
    "        \"prediction\": \"Churned\" if prediction == 1 else \"Retained\",\n",
    "        \"churn_probability\": probability[1],\n",
    "        \"retained_probability\": probability[0],\n",
    "        \"risk_level\": \"High\" if probability[1] > 0.7 else \"Medium\" if probability[0] > 0.4 else \"Low\"\n",
    "    } \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "658efc73-bbd8-4f80-8c7a-394cf12648da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict():\n",
    "    customer_data = {\n",
    "        \"CreditScore\": 400,\n",
    "        \"Geography\": \"Germany\",\n",
    "        \"Gender\": \"Female\",\n",
    "        \"Age\": 45,\n",
    "        \"Tenure\": 2,\n",
    "        \"Balance\": 100_000.0,\n",
    "        \"NumOfProducts\": 1,\n",
    "        \"HasCrCard\": \"Yes\",\n",
    "        \"IsActiveMember\": \"No\",\n",
    "        \"EstimatedSalary\": 80_000.0,  \n",
    "        \"ServiceRating\": 1\n",
    "    }\n",
    "\n",
    "    result = predict_churn(customer_data)\n",
    "    print(\"Prediction :\", result [\"prediction\"])\n",
    "    print(\"Churned Probability :\", result [\"churn_probability\"])\n",
    "    print(\"Retained Probability :\", result [\"retained_probability\"])\n",
    "    print(\"Risk Level :\", result [\"risk_level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03ba0858-2a4f-49dd-9c7c-84ce1d359077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOAD AND  EXPLORE DATASET\n",
      "============================================================\n",
      "Shape of the dataset\n",
      "(9997, 14)\n",
      "\n",
      "Check for missing values\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "EstimatedSalary    0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "Exited             0\n",
      "ServiceRating      0\n",
      "dtype: int64\n",
      "\n",
      "First five rows:\n",
      "   CustomerId   Surname  CreditScore Geography  Gender   Age  Tenure  \\\n",
      "0    15634602  Hargrave          619    France  Female  42.0       2   \n",
      "1    15647311      Hill          608     Spain  Female  41.0       1   \n",
      "2    15619304      Onio          502    France  Female  42.0       8   \n",
      "3    15701354      Boni          699    France  Female  39.0       1   \n",
      "4    15737888  Mitchell          850     Spain  Female  43.0       2   \n",
      "\n",
      "   EstimatedSalary    Balance  NumOfProducts HasCrCard IsActiveMember  Exited  \\\n",
      "0        101348.88       0.00              1       Yes            Yes       1   \n",
      "1        112542.58   83807.86              1       Yes            Yes       0   \n",
      "2        113931.57  159660.80              3        No             No       1   \n",
      "3         93826.63       0.00              2        No             No       0   \n",
      "4         79084.10  125510.82              1       Yes            Yes       0   \n",
      "\n",
      "   ServiceRating  \n",
      "0              4  \n",
      "1              5  \n",
      "2              3  \n",
      "3              5  \n",
      "4              5  \n",
      "\n",
      "Descriptive stats\n",
      "         CustomerId  CreditScore          Age       Tenure  EstimatedSalary  \\\n",
      "count  9.997000e+03  9997.000000  9997.000000  9997.000000      9997.000000   \n",
      "mean   1.569094e+07   650.545364    38.922077     5.013204    100092.222656   \n",
      "std    7.193443e+04    96.657932    10.489072     2.892364     57518.775702   \n",
      "min    1.556570e+07   350.000000    18.000000     0.000000        11.580000   \n",
      "25%    1.562853e+07   584.000000    32.000000     3.000000     50974.570000   \n",
      "50%    1.569073e+07   652.000000    37.000000     5.000000    100236.020000   \n",
      "75%    1.575323e+07   718.000000    44.000000     7.000000    149399.700000   \n",
      "max    1.581569e+07   850.000000    92.000000    10.000000    199992.480000   \n",
      "\n",
      "             Balance  NumOfProducts       Exited  ServiceRating  \n",
      "count    9997.000000    9997.000000  9997.000000    9997.000000  \n",
      "mean    76482.679807       1.530359     0.203761       2.990297  \n",
      "std     62397.174721       0.581669     0.402814       1.423382  \n",
      "min         0.000000       1.000000     0.000000       1.000000  \n",
      "25%         0.000000       1.000000     0.000000       2.000000  \n",
      "50%     97188.620000       1.000000     0.000000       3.000000  \n",
      "75%    127642.440000       2.000000     0.000000       4.000000  \n",
      "max    250898.090000       4.000000     1.000000       5.000000  \n",
      "\n",
      "Dataset Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9997 entries, 0 to 9996\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CustomerId       9997 non-null   int64  \n",
      " 1   Surname          9997 non-null   object \n",
      " 2   CreditScore      9997 non-null   int64  \n",
      " 3   Geography        9997 non-null   object \n",
      " 4   Gender           9997 non-null   object \n",
      " 5   Age              9997 non-null   float64\n",
      " 6   Tenure           9997 non-null   int64  \n",
      " 7   EstimatedSalary  9997 non-null   float64\n",
      " 8   Balance          9997 non-null   float64\n",
      " 9   NumOfProducts    9997 non-null   int64  \n",
      " 10  HasCrCard        9997 non-null   object \n",
      " 11  IsActiveMember   9997 non-null   object \n",
      " 12  Exited           9997 non-null   int64  \n",
      " 13  ServiceRating    9997 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(5)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "Exited Distribution:\n",
      "Exited\n",
      "0    7960\n",
      "1    2037\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Exited percebtage Distribution:\n",
      "Exited\n",
      "0    79.623887\n",
      "1    20.376113\n",
      "Name: proportion, dtype: float64\n",
      "============================================================\n",
      "IDENTIFY FEATURE DATASET\n",
      "============================================================\n",
      "\n",
      "Features to drop : ['CustomerId', 'Surname']\n",
      "\n",
      "Numerical features : ['CreditScore', 'Age', 'Tenure', 'EstimatedSalary', 'Balance', 'NumOfProducts', 'ServiceRating']\n",
      "Categirical features : ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
      "============================================================\n",
      "PREPARE DATASET\n",
      "============================================================\n",
      "\n",
      "Feature shape: (9997, 11)\n",
      "\n",
      "Target shape : (9997,)\n",
      "\n",
      "Feature columns list: ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'EstimatedSalary', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'ServiceRating']\n",
      "============================================================\n",
      "CREATING PREPROCESSNG PIPELINE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SPLITING DATA INTO TEST/TRAIN\n",
      "============================================================\n",
      "\n",
      "Training set size 7997\n",
      "Testing set size 2000\n",
      "Train churn distribution Exited\n",
      "0    6368\n",
      "1    1629\n",
      "Name: count, dtype: int64\n",
      "Test churn distribution Exited\n",
      "0    1592\n",
      "1     408\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "CREATING MODEL PIPELINE\n",
      "============================================================\n",
      "\n",
      "Model pipeline created successfully\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL\n",
      "============================================================\n",
      "\n",
      "Model train successfully\n",
      "\n",
      "Top 10 most important features (by coefficient magnitude)\n",
      "           feature  coefficient\n",
      "               Age     0.811030\n",
      " Geography_Germany     0.513028\n",
      "  Geography_France    -0.322457\n",
      "       Gender_Male    -0.317444\n",
      "   Geography_Spain    -0.254817\n",
      "     Gender_Female     0.253198\n",
      "IsActiveMember_Yes    -0.251379\n",
      "     HasCrCard_Yes    -0.251379\n",
      "      HasCrCard_No     0.187132\n",
      " IsActiveMember_No     0.187132\n",
      "\n",
      "============================================================\n",
      "EVALUATING MODEL\n",
      "============================================================\n",
      "\n",
      "METRICS EVALUATION\n",
      "\n",
      "Train accuracy score:, 0.7125\n",
      "\n",
      "Test accuracy score:, 0.7230\n",
      "\n",
      "Train ROC score:, 0.7690\n",
      "\n",
      "Test ROC score:, 0.7778\n",
      "\n",
      "CLASSIFICATION OF TRAIN SIZE\n",
      "\n",
      "classificatin report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Retained       0.90      0.72      0.80      6368\n",
      "     Churned       0.39      0.70      0.50      1629\n",
      "\n",
      "    accuracy                           0.71      7997\n",
      "   macro avg       0.64      0.71      0.65      7997\n",
      "weighted avg       0.80      0.71      0.74      7997\n",
      "\n",
      "\n",
      "CLASSIFICATION OF TRAIN SIZE\n",
      "\n",
      "classificatin report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Retained       0.90      0.73      0.81      1592\n",
      "     Churned       0.40      0.69      0.51       408\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.71      0.66      2000\n",
      "weighted avg       0.80      0.72      0.75      2000\n",
      "\n",
      "\n",
      "Cross Validation (5-folds)\n",
      " R2 scores: [0.75664301 0.79646734 0.75175462 0.78223991 0.74971446]\n",
      " Cross validation mean: 0.7674\n",
      " Cross validation STD: 0.0186\n",
      "\n",
      "============================================================\n",
      "SAVING MODEL\n",
      "============================================================\n",
      "Churned prediction model saved successfully\n",
      "Feature columns saved successfully\n",
      "\n",
      "============================================================\n",
      "ALL MODEL ARTIFACT SAVED SUCCESSFULLY\n",
      "============================================================\n",
      "Prediction : Churned\n",
      "Churned Probability : 0.8084351536058324\n",
      "Retained Probability : 0.1915648463941676\n",
      "Risk Level : High\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filepath = \"cleaned_bank_cusomer_churn.csv\"\n",
    "    \n",
    "    df = load_and_explore_dataset(filepath)\n",
    "\n",
    "    numerical_features, categorical_features, feature_to_drop = identify_features(df)\n",
    "\n",
    "    X, y, feature_columns = prepare_data(df, numerical_features, categorical_features, feature_to_drop)\n",
    "\n",
    "    preprocessor = create_preprossesing_pipeline(numerical_features, categorical_features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    model_pipeline = create_model_pipeline(preprocessor)\n",
    "\n",
    "    model_pipeline = train_model(model_pipeline, X_train, y_train)\n",
    "\n",
    "    metrics = evaluate_model(model_pipeline, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    save_model_artifact(model_pipeline, feature_columns)\n",
    "\n",
    "    test_predict()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
