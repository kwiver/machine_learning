{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6da53d85-359b-446f-b0c7-74fb400d3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05c1b8de-02b0-4bb7-b124-57a5988fc1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8be610f1-81d4-4b27-ae89-120e0f671999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_dataset(filepath):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"LOAD AND  EXPLORE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(\"Shape of the dataset\")\n",
    "    print(df.shape)\n",
    "    print(\"\\nCheck for missing values\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nFirst five rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDescriptive stats\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nDataset Info\")\n",
    "    print(df.info())\n",
    "    print(\"\\nExited Distribution:\")\n",
    "    print(df[\"Exited\"].value_counts())\n",
    "    print(\"\\nExited percebtage Distribution:\")\n",
    "    print(df[\"Exited\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef04ce93-07cb-40a9-af26-b48e8705b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_features(df):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"IDENTIFY FEATURE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "    # features to be droped(not useful)\n",
    "    feature_to_drop = [\n",
    "        \"CustomerId\",\n",
    "        \"Surname\"\n",
    "    ]\n",
    "\n",
    "    numerical_features = [\n",
    "        \"CreditScore\",\n",
    "        \"Age\",\n",
    "        \"Tenure\",\n",
    "        \"EstimatedSalary\",\n",
    "        \"Balance\",\n",
    "        \"NumOfProducts\",\n",
    "        \"ServiceRating\"\n",
    "    ]\n",
    "\n",
    "    categorical_features = [\n",
    "        \"Geography\",\n",
    "        \"Gender\",\n",
    "        \"HasCrCard\",\n",
    "        \"IsActiveMember\"\n",
    "    ]\n",
    "    print(\"\\nFeatures to drop :\",feature_to_drop)\n",
    "    print(\"\\nNumerical features :\", numerical_features )\n",
    "    print(\"Categirical features :\", categorical_features)\n",
    "\n",
    "    return(numerical_features, categorical_features, feature_to_drop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5126705a-71c4-4ebe-9f22-fdc02dcfbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, numerical_features, categorical_features, feature_to_drop):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PREPARE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # drop unnecessary columns\n",
    "    df_model = df.drop(columns=feature_to_drop)\n",
    "\n",
    "    # feature to use\n",
    "    X = df_model.drop(\"Exited\", axis=1)\n",
    "    # target\n",
    "    y = df_model[\"Exited\"]\n",
    "\n",
    "    print(\"\\nFeature shape:\", X.shape)\n",
    "    print(\"\\nTarget shape :\", y.shape)\n",
    "    print(\"\\nFeature columns list:\", list(X.columns))\n",
    "\n",
    "    return X, y, list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5df4796e-a734-4fa9-bda8-a0d9daf029c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprossesing_pipeline(numerical_features, categorical_features):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CREATING PREPROCESSNG PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # numerical features pipeline\n",
    "    numerical_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # categorical features pipeline\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    # column preprocesing\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numerical_pipeline, numerical_features),\n",
    "        (\"cat\", categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62bc8015-9052-4fcc-b521-9d5d4796ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SPLITING DATA INTO TEST/TRAIN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    print(\"\\nTraining set size\", X_train.shape[0])\n",
    "    print(\"Testing set size\", X_test.shape[0])\n",
    "    print(\"Train churn distribution\", y_train.value_counts())\n",
    "    print(\"Test churn distribution\", y_test.value_counts())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9bd11f9-a21d-4a23-a1f0-3aed85f54289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_pipeline(preprocessor):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CREATING MODEL PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    model_pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(\n",
    "            max_iter= 1000,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\",\n",
    "            solver=\"lbfgs\"\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print(\"\\nModel pipeline created successfully\")\n",
    "\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe57f099-3666-4588-8b7c-5197a3eb71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_pipeline, X_train, y_train):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nModel train successfully\")\n",
    "\n",
    "    #get name steps preprocessing\n",
    "    try:\n",
    "        num_features = model_pipeline.named_steps[\"preprocessor\"].transformers_[0][2]\n",
    "        cat_features = model_pipeline.named_steps[\"preprocessor\"].transformers_[1][2]\n",
    "\n",
    "        # get name stepd onehotencoder\n",
    "        onehot_encoder = model_pipeline.named_steps[\"preprocessor\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "        cat_features_names = onehot_encoder.get_feature_names_out(cat_features)\n",
    "\n",
    "        all_features_name = list(num_features) + list(cat_features_names)\n",
    "\n",
    "        # get coefficient\n",
    "        coefficient = model_pipeline.named_steps[\"classifier\"].coef_[0]\n",
    "        print(\"\\nTop 10 most important features (by coefficient magnitude)\")\n",
    "        feature_importance = pd.DataFrame({\n",
    "            \"feature\": all_features_name,\n",
    "            \"coefficient\": coefficient\n",
    "        }).sort_values(\"coefficient\", key=abs, ascending=False)\n",
    "        print(feature_importance.head(10).to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Can not extract  features names {e}\")\n",
    "\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03ba0858-2a4f-49dd-9c7c-84ce1d359077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOAD AND  EXPLORE DATASET\n",
      "============================================================\n",
      "Shape of the dataset\n",
      "(9997, 14)\n",
      "\n",
      "Check for missing values\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "EstimatedSalary    0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "Exited             0\n",
      "ServiceRating      0\n",
      "dtype: int64\n",
      "\n",
      "First five rows:\n",
      "   CustomerId   Surname  CreditScore Geography  Gender   Age  Tenure  \\\n",
      "0    15634602  Hargrave          619    France  Female  42.0       2   \n",
      "1    15647311      Hill          608     Spain  Female  41.0       1   \n",
      "2    15619304      Onio          502    France  Female  42.0       8   \n",
      "3    15701354      Boni          699    France  Female  39.0       1   \n",
      "4    15737888  Mitchell          850     Spain  Female  43.0       2   \n",
      "\n",
      "   EstimatedSalary    Balance  NumOfProducts HasCrCard IsActiveMember  Exited  \\\n",
      "0        101348.88       0.00              1       Yes            Yes       1   \n",
      "1        112542.58   83807.86              1       Yes            Yes       0   \n",
      "2        113931.57  159660.80              3        No             No       1   \n",
      "3         93826.63       0.00              2        No             No       0   \n",
      "4         79084.10  125510.82              1       Yes            Yes       0   \n",
      "\n",
      "   ServiceRating  \n",
      "0              4  \n",
      "1              5  \n",
      "2              3  \n",
      "3              5  \n",
      "4              5  \n",
      "\n",
      "Descriptive stats\n",
      "         CustomerId  CreditScore          Age       Tenure  EstimatedSalary  \\\n",
      "count  9.997000e+03  9997.000000  9997.000000  9997.000000      9997.000000   \n",
      "mean   1.569094e+07   650.545364    38.922077     5.013204    100092.222656   \n",
      "std    7.193443e+04    96.657932    10.489072     2.892364     57518.775702   \n",
      "min    1.556570e+07   350.000000    18.000000     0.000000        11.580000   \n",
      "25%    1.562853e+07   584.000000    32.000000     3.000000     50974.570000   \n",
      "50%    1.569073e+07   652.000000    37.000000     5.000000    100236.020000   \n",
      "75%    1.575323e+07   718.000000    44.000000     7.000000    149399.700000   \n",
      "max    1.581569e+07   850.000000    92.000000    10.000000    199992.480000   \n",
      "\n",
      "             Balance  NumOfProducts       Exited  ServiceRating  \n",
      "count    9997.000000    9997.000000  9997.000000    9997.000000  \n",
      "mean    76482.679807       1.530359     0.203761       2.990297  \n",
      "std     62397.174721       0.581669     0.402814       1.423382  \n",
      "min         0.000000       1.000000     0.000000       1.000000  \n",
      "25%         0.000000       1.000000     0.000000       2.000000  \n",
      "50%     97188.620000       1.000000     0.000000       3.000000  \n",
      "75%    127642.440000       2.000000     0.000000       4.000000  \n",
      "max    250898.090000       4.000000     1.000000       5.000000  \n",
      "\n",
      "Dataset Info\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 9997 entries, 0 to 9996\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CustomerId       9997 non-null   int64  \n",
      " 1   Surname          9997 non-null   str    \n",
      " 2   CreditScore      9997 non-null   int64  \n",
      " 3   Geography        9997 non-null   str    \n",
      " 4   Gender           9997 non-null   str    \n",
      " 5   Age              9997 non-null   float64\n",
      " 6   Tenure           9997 non-null   int64  \n",
      " 7   EstimatedSalary  9997 non-null   float64\n",
      " 8   Balance          9997 non-null   float64\n",
      " 9   NumOfProducts    9997 non-null   int64  \n",
      " 10  HasCrCard        9997 non-null   str    \n",
      " 11  IsActiveMember   9997 non-null   str    \n",
      " 12  Exited           9997 non-null   int64  \n",
      " 13  ServiceRating    9997 non-null   int64  \n",
      "dtypes: float64(3), int64(6), str(5)\n",
      "memory usage: 1.1 MB\n",
      "None\n",
      "\n",
      "Exited Distribution:\n",
      "Exited\n",
      "0    7960\n",
      "1    2037\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Exited percebtage Distribution:\n",
      "Exited\n",
      "0    79.623887\n",
      "1    20.376113\n",
      "Name: proportion, dtype: float64\n",
      "============================================================\n",
      "IDENTIFY FEATURE DATASET\n",
      "============================================================\n",
      "\n",
      "Features to drop : ['CustomerId', 'Surname']\n",
      "\n",
      "Numerical features : ['CreditScore', 'Age', 'Tenure', 'EstimatedSalary', 'Balance', 'NumOfProducts', 'ServiceRating']\n",
      "Categirical features : ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
      "============================================================\n",
      "PREPARE DATASET\n",
      "============================================================\n",
      "\n",
      "Feature shape: (9997, 11)\n",
      "\n",
      "Target shape : (9997,)\n",
      "\n",
      "Feature columns list: ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'EstimatedSalary', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'ServiceRating']\n",
      "============================================================\n",
      "CREATING PREPROCESSNG PIPELINE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SPLITING DATA INTO TEST/TRAIN\n",
      "============================================================\n",
      "\n",
      "Training set size 7997\n",
      "Testing set size 2000\n",
      "Train churn distribution Exited\n",
      "0    6368\n",
      "1    1629\n",
      "Name: count, dtype: int64\n",
      "Test churn distribution Exited\n",
      "0    1592\n",
      "1     408\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "CREATING MODEL PIPELINE\n",
      "============================================================\n",
      "\n",
      "Model pipeline created successfully\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL\n",
      "============================================================\n",
      "\n",
      "Model train successfully\n",
      "\n",
      "Top 10 most important features (by coefficient magnitude)\n",
      "           feature  coefficient\n",
      "               Age     0.811030\n",
      " Geography_Germany     0.513028\n",
      "  Geography_France    -0.322457\n",
      "       Gender_Male    -0.317444\n",
      "   Geography_Spain    -0.254817\n",
      "     Gender_Female     0.253198\n",
      "IsActiveMember_Yes    -0.251379\n",
      "     HasCrCard_Yes    -0.251379\n",
      "      HasCrCard_No     0.187132\n",
      " IsActiveMember_No     0.187132\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filepath = \"cleaned_bank_cusomer_churn.csv\"\n",
    "    \n",
    "    df = load_and_explore_dataset(filepath)\n",
    "\n",
    "    numerical_features, categorical_features, feature_to_drop = identify_features(df)\n",
    "\n",
    "    X, y, feature_columns = prepare_data(df, numerical_features, categorical_features, feature_to_drop)\n",
    "\n",
    "    preprocessor = create_preprossesing_pipeline(numerical_features, categorical_features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    model_pipeline = create_model_pipeline(preprocessor)\n",
    "\n",
    "    model_pipeline = train_model(model_pipeline, X_train, y_train)\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
